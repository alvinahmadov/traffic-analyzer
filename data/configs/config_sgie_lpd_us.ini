[property]
gpu-id=0
process-mode=2
net-scale-factor=1.0
offsets=103.939;116.779;123.68
model-color-format=1
labelfile-path=../labels/label_lpd_us.txt
int8-calib-file=../models/detector/us_lpd_yolov4-tiny/yolov4_tiny_usa_cal.bin
tlt-encoded-model=../models/detector/us_lpd_yolov4-tiny/yolov4_tiny_usa_deployable.etlt
model-engine-file=../models/detector/us_lpd_yolov4-tiny/yolov4_tiny_usa_deployable.etlt_b16_gpu0_int8.engine
tlt-model-key=nvidia_tlt
infer-dims=3;480;640
maintain-aspect-ratio=1
uff-input-order=0
uff-input-blob-name=Input
batch-size=16
#necerssary for correct detection
#0=Detection 1=Classifier 2=Segmentation
network-type=0
## 0=FP32, 1=INT8, 2=FP16 mode
network-mode=1
num-detected-classes=3
interval=1
#is-classifier=0
cluster-mode=3
output-blob-names=BatchedNMS
#if scaling-compute-hw = VIC, input-object-min-height need to be even and greater than or equal to (model height)/16
input-object-min-height=30
#if scaling-compute-hw = VIC, input-object-min-width need to be even and greater than or equal to( model width)/16
input-object-min-width=60
parse-bbox-func-name=NvDsInferParseCustomBatchedNMSTLT
custom-lib-path=/opt/nvidia/deepstream/deepstream/lib/libnvds_infercustomparser.so
layer-device-precision=cls/mul:fp32:gpu;box/mul_6:fp32:gpu;box/add:fp32:gpu;box/mul_4:fp32:gpu;box/add_1:fp32:gpu;cls/Reshape_reshape:fp32:gpu;box/Reshape_reshape:fp32:gpu;encoded_detections:fp32:gpu;bg_leaky_conv1024_lrelu:fp32:gpu;sm_bbox_processor/concat_concat:fp32:gpu;sm_bbox_processor/sub:fp32:gpu;sm_bbox_processor/Exp:fp32:gpu;yolo_conv1_4_lrelu:fp32:gpu;yolo_conv1_3_1_lrelu:fp32:gpu;md_leaky_conv512_lrelu:fp32:gpu;sm_bbox_processor/Reshape_reshape:fp32:gpu;conv_sm_object:fp32:gpu;yolo_conv5_1_lrelu:fp32:gpu;concatenate_6:fp32:gpu;yolo_conv3_1_lrelu:fp32:gpu;concatenate_5:fp32:gpu;yolo_neck_1_lrelu:fp32:gpu

[class-attrs-all]
pre-cluster-threshold=0.3
roi-top-offset=0
roi-bottom-offset=0
detected-min-w=0
detected-min-h=0
detected-max-w=0
detected-max-h=0
